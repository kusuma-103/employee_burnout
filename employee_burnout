!pip install pandas numpy matplotlib seaborn scikit-learn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Assuming your data is in a CSV file named 'your_data.csv'
# Replace 'your_data.csv' with the actual file name
try:
    df = pd.read_csv("employee_data.csv') 
    print("File 'employee_data.csv' loaded successfully.")
except FileNotFoundError:
    print("Error: 'employee_data.csv' not found. Please upload the file or provide the correct path.")
    df = None # Set df to None to handle the error gracefully

if df is not None:
    # ... (Your existing code to preprocess and train the model) ...
    # Example: 
    # Assuming 'Column1' is your feature and 'Column2' is your target
    X = df[['Column1']]
    y = df['Column2']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Visualizations (as provided in your original code)
    # 1. Scatter plot of Column1 vs. Column2 with regression line
    plt.figure(figsize=(8, 6))
    sns.regplot(x='Column1', y='Column2', data=df, line_kws={'color': 'red'}) # Using original df
    plt.title('Column1 vs. Column2 with Regression Line')
    plt.xlabel('Column1')
    plt.ylabel('Column2')
    plt.show()
    # 2. Residual plot
    plt.figure(figsize=(8, 6))
    residuals = y_test - y_pred
    sns.residplot(x=y_pred, y=residuals, lowess=True, line_kws={'color': 'red'})
    plt.title('Residual Plot')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.show()

    # 3. Distribution of residuals
    plt.figure(figsize=(8, 6))
    sns.histplot(residuals, kde=True)
    plt.title('Distribution of Residuals')
    plt.xlabel('Residuals')
    plt.ylabel('Frequency')
    plt.show()
